spark.hadoop.dfs.nameservices  ns1,ns2
spark.hadoop.dfs.ha.namenodes.ns1  nn1,nn2
spark.hadoop.dfs.ha.namenodes.ns2  nn3,nn4
spark.hadoop.dfs.namenode.rpc-address.ns1.nn1 hadoop-nn1.reksoft.ru:8020
spark.hadoop.dfs.namenode.rpc-address.ns1.nn2 hadoop-nn2.reksoft.ru:8020
spark.hadoop.dfs.namenode.rpc-address.ns2.nn3 hadoop-nn3.reksoft.ru:8020
spark.hadoop.dfs.namenode.rpc-address.ns2.nn4 hadoop-nn4.reksoft.ru:8020
spark.hadoop.dfs.client.failover.proxy.provider.ns1 org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
spark.hadoop.dfs.client.failover.proxy.provider.ns2 org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

; $SPARK_HOME/bin/pyspark --master "local[8]" \
; --name "WordCount-App" \
; --conf spark.hadoop.dfs.nameservices="ns1,ns2" \
; --conf spark.hadoop.dfs.ha.namenodes.ns1="nn1,nn2" \
; --conf spark.hadoop.dfs.ha.namenodes.ns2="nn3,nn4" \
; --conf spark.hadoop.dfs.namenode.rpc-address.ns1.nn1="hadoop-nn1.reksoft.ru:8020" \
; --conf spark.hadoop.dfs.namenode.rpc-address.ns1.nn2="hadoop-nn2.reksoft.ru:8020" \
; --conf spark.hadoop.dfs.namenode.rpc-address.ns2.nn3="hadoop-nn3.reksoft.ru:8020" \
; --conf spark.hadoop.dfs.namenode.rpc-address.ns2.nn4="hadoop-nn4.reksoft.ru:8020" \
; --conf spark.hadoop.dfs.client.failover.proxy.provider.ns1="org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider" \
; --conf spark.hadoop.dfs.client.failover.proxy.provider.ns2="org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"
